# ==============================================================================
# ROBOTS.TXT - Search Engine Indexing Rules
# AI Workflow Rules Framework v4.0
# ==============================================================================
#
# PURPOSE:
#   Control how search engines, AI assistants, and voice search crawl your site
#
# IMPORTANT:
#   - This is a TEMPLATE for client projects
#   - Copy to your project's public/ directory
#   - Customize based on your needs
#   - This file is PUBLIC (anyone can view it)
#
# CURRENT CONFIGURATION (Ukrainian Market Optimized):
#   ✅ Allow search engines (Google, Bing, DuckDuckGo)
#   ✅ Allow AI assistants (ChatGPT, Claude, Bard, Perplexity)
#   ✅ Allow voice search (Google Assistant, Alexa, Siri)
#   ✅ Sitemap declared
#   ❌ Block russian search engines (Yandex, Mail.ru, Rambler)
#
# WHY BLOCK RUSSIAN SERVICES:
#   - Security: Prevent data leakage to russian state servers
#   - SEO: Yandex <1% market share in Ukraine (Google 95%+)
#   - Legal: Ukrainian wartime data protection compliance
#   - See: RULES_PRODUCT.md Section 8 (Forbidden Tracking)
#
# LEARN MORE:
#   https://developers.google.com/search/docs/crawling-indexing/robots/intro
#
# ==============================================================================

# ==============================================================================
# DEFAULT RULE - ALLOW ALL
# ==============================================================================

User-agent: *
Allow: /

# This allows all search engines to index all pages
# Change "Allow: /" to "Disallow: /" to block indexing entirely

# ==============================================================================
# BLOCK SPECIFIC PATHS (Examples - uncomment as needed)
# ==============================================================================

# Block admin panel
# Disallow: /admin/

# Block API routes (if you don't want them indexed)
# Disallow: /api/

# Block user profiles (privacy)
# Disallow: /users/

# Block search results (duplicate content)
# Disallow: /search?

# Block private files
# Disallow: /private/

# Block temporary files
# Disallow: /tmp/

# ==============================================================================
# SITEMAP LOCATION
# ==============================================================================

# Tell search engines where your sitemap is
# Replace with your actual domain
Sitemap: https://yourdomain.com/sitemap.xml

# If you have multiple sitemaps:
# Sitemap: https://yourdomain.com/sitemap-pages.xml
# Sitemap: https://yourdomain.com/sitemap-posts.xml

# ==============================================================================
# CRAWL DELAY (Optional)
# ==============================================================================

# Slow down aggressive crawlers (seconds between requests)
# Uncomment if your server is getting overloaded by bots

# User-agent: *
# Crawl-delay: 10

# ==============================================================================
# SPECIFIC SEARCH ENGINES
# ==============================================================================

# Google (primary for Ukrainian market - 95%+ share)
User-agent: Googlebot
Allow: /

User-agent: Googlebot-Image
Allow: /

User-agent: Googlebot-Video
Allow: /

User-agent: Googlebot-Mobile
Allow: /

# Bing (2nd largest in Ukraine)
User-agent: Bingbot
Allow: /

User-agent: BingPreview
Allow: /

# DuckDuckGo (privacy-focused)
User-agent: DuckDuckBot
Allow: /

# ==============================================================================
# AI ASSISTANTS & AGENTS (Allow for AI-friendly indexing)
# ==============================================================================

# OpenAI (ChatGPT, GPT-4)
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

# Anthropic (Claude)
User-agent: ClaudeBot
Allow: /

User-agent: Claude-Web
Allow: /

# Google Bard/Gemini
User-agent: Google-Extended
Allow: /

# Meta AI
User-agent: FacebookBot
Allow: /

# Common Crawl (AI training datasets)
User-agent: CCBot
Allow: /

# Perplexity AI
User-agent: PerplexityBot
Allow: /

# ==============================================================================
# VOICE ASSISTANTS (Allow for voice search)
# ==============================================================================

# Google Assistant
User-agent: Googlebot
Allow: /

# Alexa (Amazon)
User-agent: ia_archiver
Allow: /

# Siri (Apple)
User-agent: Applebot
Allow: /

User-agent: Applebot-Extended
Allow: /

# ==============================================================================
# BLOCK RUSSIAN SEARCH ENGINES (Ukrainian Market Protection)
# ==============================================================================

# Yandex (russian state-controlled search engine)
# Blocked for Ukrainian market security
User-agent: Yandex
Disallow: /

User-agent: YandexBot
Disallow: /

User-agent: YandexImages
Disallow: /

User-agent: YandexVideo
Disallow: /

User-agent: YandexMedia
Disallow: /

User-agent: YandexBlogs
Disallow: /

User-agent: YandexNews
Disallow: /

User-agent: YandexMetrika
Disallow: /

# Mail.ru (russian)
User-agent: Mail.RU_Bot
Disallow: /

# Rambler (russian)
User-agent: StackRambler
Disallow: /

# ==============================================================================
# BLOCK BAD BOTS (Optional)
# ==============================================================================

# Block scrapers, spammers, and malicious bots
# Uncomment as needed

# User-agent: AhrefsBot
# Disallow: /

# User-agent: SemrushBot
# Disallow: /

# User-agent: MJ12bot
# Disallow: /

# User-agent: DotBot
# Disallow: /

# ==============================================================================
# MEDIA FILES (Optional)
# ==============================================================================

# Allow indexing images
User-agent: Googlebot-Image
Allow: /

# Allow indexing videos
User-agent: Googlebot-Video
Allow: /

# ==============================================================================
# MOBILE (Optional)
# ==============================================================================

# Allow mobile crawlers
User-agent: Googlebot-Mobile
Allow: /

# ==============================================================================
# UKRAINIAN MARKET SPECIFIC NOTES
# ==============================================================================

# This robots.txt is optimized for Ukrainian market:
#
# ✅ ALLOWED:
#   - Google (95%+ market share in Ukraine)
#   - Bing (2%+ market share)
#   - DuckDuckGo (privacy-focused users)
#   - AI Assistants (ChatGPT, Claude, Bard, Perplexity)
#   - Voice Search (Google Assistant, Alexa, Siri)
#
# ❌ BLOCKED:
#   - Yandex (russian state-controlled, <1% UA market share)
#   - Mail.ru (russian)
#   - Rambler (russian)
#
# RATIONALE:
#   - Security: Block russian surveillance vectors
#   - SEO: Focus on 95%+ market (Google)
#   - AI-Friendly: Allow AI assistants for modern discoverability
#   - Voice: Enable voice search optimization
#   - Legal: Comply with Ukrainian wartime data protection
#
# See: RULES_PRODUCT.md Section 8 (Forbidden Tracking)

# ==============================================================================
# NEXT.JS SPECIFIC
# ==============================================================================

# If using Next.js, you may want to block certain paths:

# Block Next.js build artifacts
Disallow: /_next/static/

# Allow Next.js images optimization
Allow: /_next/image

# ==============================================================================
# WORDPRESS SPECIFIC (If migrating from WordPress)
# ==============================================================================

# Block WordPress admin
# Disallow: /wp-admin/
# Disallow: /wp-login.php

# Block WordPress includes
# Disallow: /wp-includes/

# ==============================================================================
# SECURITY NOTES
# ==============================================================================

# ⚠️  robots.txt is PUBLIC
#     - Never put secrets here
#     - Disallow doesn't prevent access (just indexing)
#     - Use authentication for actual security

# ⚠️  Disallow !== Block
#     - robots.txt only asks bots to not crawl
#     - Malicious bots may ignore it
#     - Use server-side auth for sensitive pages

# ==============================================================================
# TESTING
# ==============================================================================

# Test your robots.txt:
# 1. Visit: https://yourdomain.com/robots.txt
# 2. Google Search Console: https://search.google.com/search-console/robots-txt-tester
# 3. Bing Webmaster Tools: https://www.bing.com/webmasters

# ==============================================================================
# COMMON MISTAKES TO AVOID
# ==============================================================================

# ❌ DON'T block everything (unless intentional):
#    User-agent: *
#    Disallow: /
#    ^ This blocks ALL search engines from indexing your site!

# ❌ DON'T forget sitemap:
#    Without sitemap, search engines may not find all pages

# ❌ DON'T use wildcards incorrectly:
#    Disallow: /*.php  # Wrong syntax
#    Use: Disallow: /admin/*.php  # Correct

# ❌ DON'T rely on robots.txt for security:
#    It's a suggestion, not authentication

# ==============================================================================
# BEST PRACTICES
# ==============================================================================

# ✅ Keep it simple (start with Allow: / for everything)
# ✅ Declare your sitemap
# ✅ Test with Google Search Console
# ✅ Block duplicate content (search results, filters)
# ✅ Allow important pages for SEO
# ✅ Update when site structure changes
# ✅ Monitor crawl errors in Search Console

# ==============================================================================
# SUPPORT
# ==============================================================================

# Questions about robots.txt?
# - Google Guide: https://developers.google.com/search/docs/crawling-indexing/robots/intro
# - Bing Guide: https://www.bing.com/webmasters/help/how-to-create-a-robots-txt-file-cb7c31ec
# - Test tool: https://www.google.com/webmasters/tools/robots-testing-tool

# ==============================================================================
# END OF FILE
# ==============================================================================
