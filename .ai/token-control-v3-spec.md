# Token Control v3.0 â€” Architecture Specification

> **Status:** Implementation in progress
> **Author:** AI Financial Analyst with 10 years experience (fictional persona)
> **Date:** 2026-02-03
> **Version:** 3.0.0

---

## Executive Summary

Token Control v3.0 introduces **intelligent, confidence-based budget management** for AI coding sessions. Unlike v2.0 (reactive monitoring), v3.0 is **proactive** â€” showing cost estimates BEFORE execution and learning from actual usage to improve accuracy over time.

**Key Innovation:** Control without dictatorship. Inform, don't restrict.

---

## Philosophy

### Core Principles

1. **Default to YES** â€” System helps, doesn't block
2. **Inform, don't restrict** â€” Show cost, offer alternatives, let user decide
3. **Learn and adapt** â€” Improve accuracy with variance tracking
4. **Graceful degradation** â€” Work even if tracking disabled
5. **Zero overhead** â€” Don't add friction to simple tasks

### The 10-15% Rule

Save 10-15% tokens per session by **eliminating waste**, not cutting quality:
- Redundant file reads
- Exploratory reads "just in case"
- Over-explanation of obvious things
- Premature execution before clarification
- Sequential operations that could be batched

---

## Architecture (4 Layers)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: Budget Management (Safety Net)                    â”‚
â”‚ â€¢ Emergency reserve protection (10-15%)                     â”‚
â”‚ â€¢ Zone monitoring & transitions                             â”‚
â”‚ â€¢ Multi-session forecasting                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: Learning Engine (Intelligence)                    â”‚
â”‚ â€¢ Variance tracking (estimate vs actual)                    â”‚
â”‚ â€¢ Pattern recognition (similar tasks)                       â”‚
â”‚ â€¢ Confidence scoring (HIGH/MEDIUM/LOW)                      â”‚
â”‚ â€¢ Self-calibration (adjust thresholds)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: Approval Flow (User Experience)                   â”‚
â”‚ â€¢ Progressive disclosure (show details when needed)         â”‚
â”‚ â€¢ Smart auto-approve (safe operations)                      â”‚
â”‚ â€¢ Batch optimization suggestions                            â”‚
â”‚ â€¢ Deferred execution queue                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Estimation Engine (Core)                          â”‚
â”‚ â€¢ Request complexity analysis                               â”‚
â”‚ â€¢ Task type classification                                  â”‚
â”‚ â€¢ Historical pattern matching                               â”‚
â”‚ â€¢ Risk factor scoring                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Layer 1: Estimation Engine

### Request Analysis Pipeline

```
User Request
    â†“
[1. Parse & Classify]
    â€¢ Task type: read/write/refactor/analyze/implement
    â€¢ Scope: micro/small/medium/large/critical
    â€¢ Complexity: simple/moderate/complex/unknown
    â†“
[2. Base Estimation]
    â€¢ Analysis phase tokens
    â€¢ Execution phase tokens
    â€¢ Safety buffer (15%)
    â†“
[3. Historical Matching]
    â€¢ Find similar tasks in variance_history
    â€¢ Calculate average actual cost
    â€¢ Compute typical variance
    â†“
[4. Risk Assessment]
    â€¢ Unknown scope? +30%
    â€¢ Multiple files? +20%
    â€¢ External dependencies? +25%
    â€¢ User said "just/simple"? +40% (ironic but true)
    â†“
[5. Confidence Scoring]
    â€¢ HIGH (Â±15%): Known task, clear scope, history available
    â€¢ MEDIUM (Â±30%): Moderate unknowns, some history
    â€¢ LOW (Â±50%): Many unknowns, no history
    â†“
[OUTPUT: Estimate + Confidence]
```

### Task Size Classification

| Size | Token Range | Auto-Approve | Checkpoint Strategy |
|------|-------------|--------------|---------------------|
| **MICRO** | <5k | âœ… Yes (silent) | None |
| **SMALL** | 5-15k | âœ… Yes (brief) | None |
| **MEDIUM** | 15-40k | âš ï¸ User approval | 1 at 50% (if MEDIUM confidence) |
| **LARGE** | 40-80k | ğŸŸ  Mandatory discussion | 2 at 33% and 66% (if LOW confidence) |
| **CRITICAL** | >80k | ğŸ”´ Full breakdown + alternatives | After analysis + every 25k |

---

## Layer 2: Approval Flow

### Progressive Cost Gates

#### MICRO Tasks (<5k tokens)
```markdown
âœ… Auto-approve, silent execution
No estimate shown unless //VERBOSE mode

Example:
User: "Fix typo in README line 42"
AI: [executes silently, shows result]
```

#### SMALL Tasks (5-15k tokens)
```markdown
âš ï¸ Brief estimate, auto-approve in Green zone

[QUICK ESTIMATE]
Task: "Update auth function"
Cost: ~12k tokens (6% of daily limit)
Confidence: HIGH (Â±15%)

Proceeding... [or show "Approve? YES/no" if user.preference.confirm_small = true]
```

#### MEDIUM Tasks (15-40k tokens)
```markdown
ğŸŸ¡ MANDATORY full breakdown & explicit approval

[TOKEN ESTIMATE]
Request: "Refactor authentication middleware"

Cost breakdown:
â”Œâ”€ Analysis phase
â”‚  â”œâ”€ Reading files (auth.ts, middleware.ts, types.ts): ~5k
â”‚  â”œâ”€ Dependency analysis: ~3k
â”‚  â””â”€ Subtotal: ~8k
â”‚
â”œâ”€ Execution phase
â”‚  â”œâ”€ Refactoring: ~18k
â”‚  â”œâ”€ Testing: ~6k
â”‚  â”œâ”€ Documentation: ~3k
â”‚  â””â”€ Subtotal: ~27k
â”‚
â””â”€ Safety buffer (15%): ~5k
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   TOTAL: ~40k tokens

Confidence: MEDIUM (Â±30%)
Based on: 3 similar refactor tasks (avg 38k actual)

Budget impact:
â€¢ Available: 149k
â€¢ After task: ~109k (54% remaining)
â€¢ Status: ğŸŸ¢ Green â†’ ğŸŸ¢ Green

[APPROVE SPEND?] YES / ADJUST / DECLINE
```

#### LARGE Tasks (40-80k tokens)
```markdown
ğŸŸ  Detailed breakdown + alternatives + staging

[HIGH COST ALERT]
Request: "Implement complete user dashboard"

Full implementation: ~65k tokens

âš ï¸ This will consume 33% of your daily limit

Alternatives:
1. FULL (~65k): Complete implementation today
   â€¢ All features, tests, docs
   â€¢ Will move to ğŸŸ¡ Moderate zone

2. STAGED (~25k today, ~40k tomorrow):
   â€¢ Today: Core UI components + basic data
   â€¢ Tomorrow: Advanced features + optimization
   â€¢ Stay in ğŸŸ¢ Green zone both days

3. MINIMAL (~35k): Essential features only
   â€¢ Core dashboard, skip advanced features
   â€¢ Stay in ğŸŸ¢ Green zone

Recommendation: Option 2 (STAGED) for better budget control

Your choice? [1/2/3]
```

#### CRITICAL Tasks (>80k or zone transition to Red)
```markdown
ğŸ”´ MANDATORY discussion + risk analysis

[CRITICAL COST WARNING]
Request: "Complete system architecture refactor"

Estimated cost: ~120k tokens (60% of daily limit!)

âš ï¸ RISKS:
â€¢ Will move to ğŸ”´ Critical zone (>90%)
â€¢ Emergency reserve will be exhausted
â€¢ No budget for unexpected issues
â€¢ Forces end-of-day commit

This should be split across multiple sessions.

Recommended approach:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Day 1: Analysis + Planning (~30k)
â€¢ Review current architecture
â€¢ Create detailed refactor plan
â€¢ Identify critical paths

Day 2: Core Implementation (~50k)
â€¢ Implement main components
â€¢ Unit tests

Day 3: Integration + Polish (~40k)
â€¢ Integration tests
â€¢ Documentation
â€¢ Final validation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 120k across 3 days (safe budget each day)

Proceed with Day 1 planning? [YES/MODIFY/DECLINE]
```

### Smart Batching Detection

AI automatically detects batch opportunities:

```markdown
[OPTIMIZATION OPPORTUNITY]

Detected pattern: Multiple related file updates

You asked:
â”œâ”€ "Update auth.ts"
â”œâ”€ "Update middleware.ts"
â””â”€ "Update types.ts" (all related to auth)

Cost analysis:
â€¢ Sequential: 15k + 12k + 8k = 35k tokens
â€¢ Batched: 7k (read all) + 4k (plan) + 12k (execute) = 23k

ğŸ’° SAVE 12k tokens (34%)

Batch them? [YES] / [NO, keep separate]
```

### Deferred Execution Queue

Allow postponing non-critical work:

```markdown
[STAGE COMPLETE] Core implementation done
Used: 28k tokens (estimate was 25k, +12% variance)

Next in queue:
â”Œâ”€ Unit tests (~8k)
â”œâ”€ Integration tests (~12k)
â”œâ”€ Documentation (~5k)
â””â”€ Total remaining: ~25k

Your budget:
â€¢ Used today: 78k (39%)
â€¢ Available: 122k (61%)
â€¢ After queue: ~97k (48%) ğŸŸ¢ Green

Options:
1. CONTINUE ALL: Execute full queue (~25k)
2. TESTS ONLY: Unit + integration, defer docs (~20k)
3. ESSENTIAL: Unit tests only, defer rest (~8k)
4. DEFER ALL: Commit current work, queue for tomorrow

Recommendation: Option 1 (you have good budget remaining)

Your choice? [1/2/3/4]
```

---

## Layer 3: Learning Engine

### Variance Tracking

After each task, record:

```json
{
  "task_id": "uuid",
  "date": "2026-02-03T14:30:00Z",
  "request_brief": "Refactor auth middleware",
  "task_type": "refactor",
  "scope": "medium",
  "estimated_tokens": 40000,
  "actual_tokens": 45000,
  "variance_tokens": 5000,
  "variance_percent": 12.5,
  "confidence_level": "medium",
  "reason": "Additional type definitions needed",
  "files_involved": 4,
  "files_estimated": 3
}
```

### Pattern Recognition

After 10+ tasks, AI learns patterns:

```python
# Pseudocode
patterns = {
    "refactor": {
        "avg_variance": +35%,
        "reason": "Scope creep, additional files discovered"
    },
    "simple_fix": {
        "avg_variance": +5%,
        "reason": "Usually accurate"
    },
    "implement_feature": {
        "avg_variance": +40%,
        "reason": "Requirements clarification during work"
    }
}

# When estimating new "refactor" task:
base_estimate = 30k
adjusted = base_estimate * 1.35  # Apply learned +35%
confidence = "MEDIUM" if history.count > 5 else "LOW"
```

### Confidence Calculation

```python
def calculate_confidence(request, history):
    score = 100

    # Deductions
    if "refactor" in request.lower():
        score -= 20  # Scope uncertainty
    if "system" in request.lower():
        score -= 15  # Multiple files likely
    if not history.similar_tasks:
        score -= 25  # No learning data
    if request.words < 5:
        score -= 20  # Vague requirement

    # Bonuses
    if history.similar_tasks > 5:
        score += 15  # Good data
    if "fix typo" in request.lower():
        score += 20  # Very specific
    if files_known and files_count == 1:
        score += 10  # Limited scope

    # Map to levels
    if score >= 85: return "HIGH", "Â±15%"
    if score >= 65: return "MEDIUM", "Â±30%"
    return "LOW", "Â±50%"
```

### Self-Calibration

After 30 days, system analyzes user patterns:

```markdown
[SYSTEM SELF-ANALYSIS] Month 1 Complete

Your patterns:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Tasks completed: 47
Total tokens: 1.8M (90% of monthly limit)
Avg per task: 38k

Approval behavior:
â€¢ Auto-approved: 89% (42 tasks)
â€¢ Modified: 8% (4 tasks)
â€¢ Declined: 3% (1 task)

Work style:
â€¢ Prefer larger batches (avg 38k/task vs 25k typical)
â€¢ Morning sessions: 68% of daily tokens
â€¢ Rarely adjust estimates (high trust)
â€¢ Complete work in 2-3 focused sessions/day

Variance accuracy:
â€¢ Month start: Â±45% (learning phase)
â€¢ Month end: Â±22% (improved!)
â€¢ Current confidence: 74% of tasks HIGH

Optimization opportunities:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. RAISE auto-approve threshold
   From: 15k â†’ To: 25k
   Reason: You trust estimates, reduce interruptions
   Impact: 15 fewer approvals/month

2. ENABLE batch mode default
   Reason: You prefer larger tasks
   Impact: ~12% token savings detected

3. LOWER checkpoint frequency
   Reason: 95% of checkpoints you say "continue"
   Impact: Smoother workflow

Apply suggestions? [YES/REVIEW/NO]
```

---

## Layer 4: Budget Management

### Emergency Reserve Protection

Always keep 10-15% for unexpected issues:

```markdown
[BUDGET WARNING]

Request: Large implementation (~70k tokens)

Current situation:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total daily: 200k
Used: 135k (67%)
Available: 65k (33%)
Emergency reserve: 20k (10% protected)
Safe available: 45k
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸ Task (70k) exceeds safe available (45k)

Why reserves matter:
â€¢ Bug fixes during implementation
â€¢ User clarifications mid-work
â€¢ Testing reveals issues
â€¢ Documentation updates
â€¢ Rollback scenarios

Options:
1. REDUCE SCOPE: Fit in 40k, keep reserve
2. SPLIT: 35k today, 35k tomorrow
3. PROCEED (RISKY): Use reserve, no safety net
4. DEFER: Start tomorrow with fresh 200k

Recommendation: Option 2 (SPLIT)

Your choice? [1/2/3/4]
```

### Zone Transition Warnings

```markdown
[ZONE TRANSITION ALERT]

Current: ğŸŸ¢ Green (48% used)
After task: ğŸŸ¡ Moderate (63% used)

What changes in Moderate zone:
â€¢ Auto-approve threshold: 15k â†’ 8k
â€¢ Verbosity: Normal â†’ Brief
â€¢ Diff-only mode: Activates
â€¢ Context compression: More aggressive

This is normal progression. Continue? [YES/NO]
```

### Multi-Session Forecasting

```markdown
[SESSION FORECAST]

Today's plan:
â”œâ”€ Task A: ~35k (approved)
â”œâ”€ Task B: ~28k (in queue)
â””â”€ Task C: ~40k (proposed)
Total: ~103k tokens

Budget projection:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Current: 52k used (26%)
After A: ~87k (43%) ğŸŸ¢
After B: ~115k (57%) ğŸŸ¡ â† Zone change
After C: ~155k (77%) ğŸŸ 

Recommendation:
â€¢ Complete A + B today (~115k total)
â€¢ Defer C to tomorrow (fresh budget)
â€¢ Keeps you in ğŸŸ¡ Moderate, not ğŸŸ  Caution

Proceed with A + B only? [YES/NO/ADJUST]
```

---

## Integration with v2.0

### Backwards Compatibility

v3.0 gracefully extends v2.0:

```json
// Old v2.0 token-limits.json still works
{
  "provider": "anthropic",
  "plan": "pro",
  "daily_limit": 150000,
  "tracking_enabled": true
}

// v3.0 adds optional fields
{
  "provider": "anthropic",
  "plan": "pro",
  "daily_limit": 150000,
  "tracking_enabled": true,

  // NEW in v3.0 (optional)
  "auto_approve_thresholds": {
    "green_zone": 15000,
    "moderate_zone": 8000,
    "caution_zone": 3000,
    "critical_zone": 0
  },
  "session_tracking": {
    "used": 0,
    "committed": 0,
    "available": 150000
  },
  "variance_history": [],
  "learning_enabled": true
}
```

### Migration Path

1. **Day 1:** System works with old schema, no estimates shown
2. **User updates schema:** v3.0 features activate
3. **Weeks 1-2:** Learning phase, LOW confidence estimates
4. **Week 3+:** Improved accuracy, self-calibration kicks in

No breaking changes. Pure enhancement.

---

## CLI Commands (Power Users)

```bash
# Show detailed budget status
//TOKENS
[OUTPUT]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
SESSION BUDGET
Used:      52k â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (26%)
Committed: 35k â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (17%)
Available: 113k â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ (56%)
Reserve:   20k (10% protected)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# Get estimate without executing
//ESTIMATE "refactor user authentication"
[OUTPUT]
Task: "refactor user authentication"
Estimate: ~42k tokens
Confidence: MEDIUM (Â±30%)
Based on: 5 similar tasks

# Show variance learning statistics
//VARIANCE
[OUTPUT]
Variance Analysis (last 30 days)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total tasks: 34
Avg variance: +18%
Best estimate: "fix bug" (+3%)
Worst estimate: "refactor system" (+52%)

Improving: âœ“ (was Â±35%, now Â±22%)

# Suggest batch optimizations
//BATCH
[OUTPUT]
Potential batching opportunities:
â€¢ update_auth.ts + update_middleware.ts
  Save: ~8k tokens (28%)

# Adjust auto-approve threshold
//CONFIG auto_approve 20000
[OUTPUT]
âœ“ Auto-approve threshold: 15k â†’ 20k
Impact: ~10 fewer approvals/month

# Export analytics
//EXPORT tokens-report.json
[OUTPUT]
âœ“ Exported to .ai/tokens-report.json
Contains: 34 tasks, variance data, patterns
```

---

## Success Metrics

### Week 1
- âœ… 100% of tasks >5k show pre-flight estimate
- âœ… User approves/declines, not surprised by costs
- âœ… Variance tracking active
- âœ… At least 8% tokens saved (batching + deferring)

### Month 1
- âœ… Variance <30% on medium tasks
- âœ… Confidence HIGH for 50%+ tasks
- âœ… Zero emergency limit hits
- âœ… 10-15% tokens saved vs v2.0 baseline

### Month 3
- âœ… Variance <20% on familiar task types
- âœ… Confidence HIGH for 70%+ tasks
- âœ… Self-calibration active
- âœ… System suggests optimizations proactively

---

## Implementation Roadmap

### Stage 1: Architecture (DONE)
âœ“ This specification document

### Stage 2: RULES_CORE.md Update
Update Section 2 (Token Management):
- 2.14: Pre-Flight Token Approval Protocol
- 2.15: Confidence-Based Estimation
- 2.16: Learning Engine & Variance Tracking
- 2.17: Emergency Reserve Management
- 2.18: Optimization Strategies

### Stage 3: token-limits.json v3.0
Add new schema fields:
- auto_approve_thresholds
- session_tracking
- variance_history
- learning_enabled

### Stage 4: Documentation
- TOKEN_USAGE.md: Real scenarios
- CHEATSHEET.md: CLI commands
- Examples for each task size

### Stage 5: Validation
- Test all flows
- Verify backwards compatibility
- Validate learning algorithm logic

---

## Appendix: Waste Types & Fixes

| Waste Type | Example | Fix | Savings |
|------------|---------|-----|---------|
| **Redundant reads** | Reading same file 3x in one session | Session cache | ~40% |
| **Exploratory reads** | "Let me check 5 files to understand..." | Targeted reads only | ~60% |
| **Over-explanation** | Explaining obvious typo fixes | Brief mode for simple tasks | ~30% |
| **Premature execution** | Implementing before clarification | Discuss â†’ Approve â†’ Execute | ~100% on wrong path |
| **Sequential ops** | Update A, then B, then C separately | Batch operations | ~35% |

Total potential savings: **10-15% per session** without quality loss.

---

**End of Specification**
**Version:** 3.0.0
**Status:** Ready for implementation
**Next:** Update RULES_CORE.md Section 2
